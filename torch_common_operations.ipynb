{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-14T19:18:30.362791Z",
     "end_time": "2023-04-14T19:18:30.995324Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[-0.7150],\n          [-0.2528],\n          [-0.9498]],\n\n         [[ 1.9665],\n          [ 1.3879],\n          [-1.3074]],\n\n         [[ 0.4186],\n          [ 0.9843],\n          [ 0.4373]]],\n\n\n        [[[ 0.4156],\n          [ 0.2733],\n          [-0.8496]],\n\n         [[-0.1488],\n          [ 0.2617],\n          [ 0.2777]],\n\n         [[ 0.2505],\n          [ 0.3674],\n          [-0.8372]]]])"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#创建标准正态分布矩阵，维度可变\n",
    "a = torch.randn(2, 3, 3, 1)\n",
    "a"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T21:37:00.031963Z",
     "end_time": "2023-04-11T21:37:00.076697Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(1.)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#创建常数tensor\n",
    "torch.tensor(1.)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T21:37:00.076697Z",
     "end_time": "2023-04-11T21:37:00.122704Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 3, 3, 1])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#输出a的维度\n",
    "a.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T21:37:00.092704Z",
     "end_time": "2023-04-11T21:37:00.123704Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 3, 1])\n",
      "torch.Size([2, 3, 3, 1])\n",
      "torch.Size([])\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "#输出a在矩阵形式下和常量形式下的形状\n",
    "a = torch.randn(2, 3, 3, 1)\n",
    "print(a.size())\n",
    "print(a.shape)\n",
    "a = torch.tensor(3.9)\n",
    "print(a.size())\n",
    "print(a.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T21:37:00.109703Z",
     "end_time": "2023-04-11T21:37:00.123704Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.9000)\n",
      "tensor([3.9000])\n"
     ]
    }
   ],
   "source": [
    "#torch也可以指定其中的数据类型,torch.Tensor默认为float64\n",
    "print(torch.tensor(3.9, dtype=torch.float32))\n",
    "print(torch.FloatTensor([3.9]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T21:37:00.125703Z",
     "end_time": "2023-04-11T21:37:00.141704Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#通过numpy创建全1矩阵\n",
    "print(np.ones([2, 3]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T21:37:00.140704Z",
     "end_time": "2023-04-11T21:37:00.199704Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3]\n",
      "2\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "#通过numpy数组转换为tensor\n",
    "a = torch.from_numpy(np.ones([2, 3]))\n",
    "print(list(a.shape))\n",
    "#返回tensor的维度数量\n",
    "print(a.dim())\n",
    "#输出tensor的元素数量\n",
    "print(a.numel())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T21:37:00.155704Z",
     "end_time": "2023-04-11T21:37:00.217704Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "#创建全0矩阵\n",
    "a = torch.zeros([2, 3])\n",
    "print(a)\n",
    "#输出a某个维度下的通道数量\n",
    "print(a.size(0))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T21:37:00.170704Z",
     "end_time": "2023-04-11T21:37:00.217704Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "array([2. , 3.3])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#创建数组列表\n",
    "np.array([2, 3.3])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T21:37:00.187703Z",
     "end_time": "2023-04-11T21:37:00.218704Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[2.6405e-06, 1.0368e-11, 1.6614e-07],\n        [8.5410e+20, 2.1744e+23, 2.5812e-06]])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#创建未初始化的tensor\n",
    "torch.empty(2, 3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T21:37:00.202704Z",
     "end_time": "2023-04-11T21:37:00.218704Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "'torch.DoubleTensor'"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#设置默认类型\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "torch.empty(2, 3).type()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T21:37:00.216704Z",
     "end_time": "2023-04-11T21:37:00.294712Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6143, 0.8127, 0.2493],\n",
      "        [0.4560, 0.2913, 0.9702]])\n",
      "tensor([[ 1.2416,  0.0534,  0.9366],\n",
      "        [ 0.5682,  1.0035, -1.9146]])\n"
     ]
    }
   ],
   "source": [
    "#创建均匀分布的tensor，范围为[0,1)\n",
    "a = torch.rand(2, 3)\n",
    "print(a)\n",
    "#randn_like(a)创建与a形状相同的tensor\n",
    "a = torch.randn_like(a)\n",
    "print(a)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T21:37:00.233704Z",
     "end_time": "2023-04-11T21:37:00.310717Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.2642, 1.5173, 1.4778, 1.2465, 1.5079, 1.4614, 0.5066, 0.6595, 0.8414,\n",
      "        0.9782])\n",
      "tensor([[9., 9., 9.],\n",
      "        [9., 9., 9.]])\n"
     ]
    }
   ],
   "source": [
    "#创建自定义的正态分布\n",
    "a = torch.normal(mean=torch.full([10], 1.0), std=torch.arange(1, 0, -0.1))\n",
    "print(a)\n",
    "#创建自定义常数填充的tensor\n",
    "a = torch.full([2, 3], 9.0)\n",
    "print(a)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T21:37:00.248705Z",
     "end_time": "2023-04-11T21:37:00.326720Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0000,  2.5000,  5.0000,  7.5000, 10.0000])\n",
      "tensor([1.0000, 0.5623, 0.3162, 0.1778, 0.1000])\n"
     ]
    }
   ],
   "source": [
    "#创建等差数列\n",
    "print(torch.linspace(0, 10, steps=5))\n",
    "#创建等比数列,默认底数为10\n",
    "print(torch.logspace(0, -1, steps=5))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T21:37:00.264704Z",
     "end_time": "2023-04-11T21:37:00.327722Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0.],\n        [0., 0., 1., 0., 0.]])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#创建单位矩阵\n",
    "torch.eye(3,5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T21:37:00.280704Z",
     "end_time": "2023-04-11T21:37:00.327722Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1])\n",
      "tensor([[0.5840, 0.4875, 0.2912, 0.6534],\n",
      "        [0.0105, 0.1423, 0.0882, 0.9521],\n",
      "        [0.2439, 0.5700, 0.8023, 0.7986]])\n",
      "tensor([[0.5840, 0.4875, 0.2912, 0.6534],\n",
      "        [0.0105, 0.1423, 0.0882, 0.9521]])\n"
     ]
    }
   ],
   "source": [
    "#创建0到n随机打乱的数列，用于shuffle\n",
    "idx=torch.randperm(2)\n",
    "print(idx)\n",
    "a=torch.rand(3,4)\n",
    "print(a)\n",
    "#按照idx中的顺序输出batchsize中的几个\n",
    "print(a[idx])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T21:37:00.296712Z",
     "end_time": "2023-04-11T21:37:00.327722Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n",
      "torch.Size([2, 3, 28, 28])\n",
      "torch.Size([2, 2, 28, 28])\n",
      "torch.Size([2, 28, 28])\n",
      "torch.Size([2, 3, 28, 3])\n",
      "tensor([ 1.9714,  0.7016, -0.1678])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([1.9714, 0.7016, 1.8111, 0.9175])"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#索引与切片\n",
    "a=torch.randn(2,3,28,28)\n",
    "print(a[0].shape)\n",
    "print(a[:2].shape)\n",
    "print(a[:2,1:,:,:].shape)\n",
    "print(a[:2,-1,:,:].shape)\n",
    "print(a.index_select(3,torch.tensor([0,1,2])).shape)\n",
    "x=torch.randn(3,4)\n",
    "mask=x.ge(0.5)\n",
    "#take选择tensor展平后的序数\n",
    "print(torch.take(x,torch.tensor([0,3,5])))\n",
    "#masked_select根据掩码矩阵进行选择\n",
    "torch.masked_select(x,mask)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T21:37:00.311717Z",
     "end_time": "2023-04-11T21:37:00.404722Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3998, 0.6095, 0.6115,  ..., 0.2285, 0.2856, 0.9434],\n",
      "        [0.8531, 0.5300, 0.9844,  ..., 0.3234, 0.7378, 0.2208],\n",
      "        [0.4422, 0.9050, 0.4034,  ..., 0.4003, 0.8965, 0.5094],\n",
      "        [0.4891, 0.7168, 0.4915,  ..., 0.8313, 0.2751, 0.1454]])\n",
      "torch.Size([1, 4, 1, 28, 28])\n",
      "torch.Size([4, 28, 28])\n",
      "torch.Size([4, 3, 28, 28])\n",
      "torch.Size([16, 3, 28, 28])\n",
      "torch.Size([28, 28])\n"
     ]
    }
   ],
   "source": [
    "a=torch.rand(4,1,28,28)\n",
    "#view可以将矩阵变形\n",
    "print(a.view(4,28*28))\n",
    "#unsqueeze可以在指定位置增加维度\n",
    "print(a.unsqueeze(0).shape)\n",
    "#squeeze可以去除指定位置的维度,但是该维度必须为1\n",
    "print(a.squeeze(1).shape)\n",
    "#expend可以将维度为1的进行扩展，方法为复制\n",
    "print(a.expand(4,3,28,28).shape)\n",
    "#repeat可以将指定维度进行重复\n",
    "print(a.repeat(4,3,1,1).shape)\n",
    "#t()可以将矩阵转置\n",
    "print(a[0,0,:,:].t().shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T21:37:00.327722Z",
     "end_time": "2023-04-11T21:37:00.409722Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 28, 28, 3])\n",
      "torch.Size([3, 28, 28, 4])\n",
      "(4, 28, 28, 3)\n"
     ]
    }
   ],
   "source": [
    "#permute可以将维度按照指定顺序排列，transpose可以交换指定维度，使用后尽量加contiguous\n",
    "a=torch.rand(4,3,28,28)\n",
    "print(a.transpose(1,3).contiguous().shape)\n",
    "print(a.permute(1,2,3,0).contiguous().shape)\n",
    "#将tensor转为numpy数组\n",
    "a=a.numpy()\n",
    "#numpy的transpose可以将维度按照某个顺序重新排列\n",
    "print(a.transpose(0,3,2,1).shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T21:37:00.344722Z",
     "end_time": "2023-04-11T21:37:00.409722Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(True)\n",
      "tensor(False)\n"
     ]
    }
   ],
   "source": [
    "#eq可以进行元素级别的比较，返回一个bool类型的tensor,all可以判断所有元素是否为True,any可以判断是否有一个元素为True\n",
    "a=torch.rand(4,3,28,28)\n",
    "print(torch.all(torch.tensor([True,False,True])))\n",
    "a2=torch.rand_like(a)\n",
    "print(torch.all(torch.eq(a,a2)))\n",
    "print(torch.any(torch.tensor([True,False,True])))\n",
    "print(torch.any(torch.eq(a,a2)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T21:37:00.362722Z",
     "end_time": "2023-04-11T21:37:00.410722Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 32, 8])\n",
      "torch.Size([4, 3, 2, 16, 32])\n",
      "torch.Size([2, 4, 3, 16, 32])\n",
      "torch.Size([1, 4, 3, 16, 32])\n"
     ]
    }
   ],
   "source": [
    "#tensor具有广播机制，可以将维度不同的tensor进行运算，但是维度必须为1或者缺失，我的评价是尽量别用混淆视听\n",
    "#torch.cat可以将tensor按照指定维度进行拼接\n",
    "a=torch.rand(4,32,8)\n",
    "b=torch.rand(5,32,8)\n",
    "print(torch.cat([a,b],dim=0).shape)\n",
    "#stack可以将tensor按照指定维度进行堆叠\n",
    "a=torch.rand(4,3,16,32)\n",
    "b=torch.rand(4,3,16,32)\n",
    "print(torch.stack([a,b],dim=2).shape)\n",
    "#split可以将tensor按照指定维度进行切分\n",
    "c=torch.stack([a,b],dim=0)\n",
    "#[]指定每个块的维度或者输入数字指定块大小\n",
    "aa,bb=c.split([1,1],dim=0)\n",
    "d=c.split(1,dim=0)\n",
    "print(c.shape)\n",
    "print(d.shape)\n",
    "print(aa.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T22:04:09.302434Z",
     "end_time": "2023-04-11T22:04:09.307435Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5383, 1.1240, 1.0319, 1.5863],\n",
      "        [1.0658, 1.5687, 1.2679, 1.8527],\n",
      "        [1.2618, 1.6943, 1.0569, 1.6539]])\n",
      "tensor([[0.5383, 1.1240, 1.0319, 1.5863],\n",
      "        [1.0658, 1.5687, 1.2679, 1.8527],\n",
      "        [1.2618, 1.6943, 1.0569, 1.6539]])\n",
      "tensor([1.1567, 2.1297, 1.9570])\n",
      "tensor([1.1567, 2.1297, 1.9570])\n",
      "tensor([[0.9138, 0.8833, 1.0083],\n",
      "        [1.5576, 1.8807, 2.0061],\n",
      "        [1.4142, 1.9953, 1.9863]])\n",
      "tensor([[0.0171, 0.1470, 0.0854, 0.4003],\n",
      "        [0.4331, 0.6859, 0.2790, 0.8084],\n",
      "        [0.7295, 0.9096, 0.1007, 0.4904]])\n",
      "tensor([[1.1395, 1.4673, 1.3394, 1.8826],\n",
      "        [1.9311, 2.2891, 1.6959, 2.4574],\n",
      "        [2.3493, 2.5953, 1.3734, 2.0143]])\n",
      "tensor([[-2.0356, -0.9586, -1.2302, -0.4578],\n",
      "        [-0.4184, -0.1885, -0.6382, -0.1064],\n",
      "        [-0.1577, -0.0474, -1.1480, -0.3563]])\n",
      "tensor(0.9537)\n",
      "tensor(0.6327)\n",
      "tensor([[0.2000, 0.3834, 0.2922, 0.6327],\n",
      "        [0.6581, 0.8000, 0.5282, 0.8000],\n",
      "        [0.8000, 0.8000, 0.3173, 0.7003]])\n",
      "tensor([1.0861, 1.3200, 0.6820, 1.3035])\n",
      "tensor([1.6428, 2.1653, 1.1377, 2.2320])\n",
      "tensor([0.5476, 0.7218, 0.3792, 0.7440])\n",
      "tensor([0.0734, 0.3028, 0.0490, 0.3983])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([2, 2, 1, 1])\n",
      "tensor([[2, 2, 1, 1]])\n",
      "torch.return_types.kthvalue(\n",
      "values=tensor([0.6581, 0.8282, 0.3173, 0.7003]),\n",
      "indices=tensor([1, 1, 2, 2]))\n",
      "torch.return_types.topk(\n",
      "values=tensor([[0.8541, 0.9537, 0.5282, 0.8991],\n",
      "        [0.6581, 0.8282, 0.3173, 0.7003]]),\n",
      "indices=tensor([[2, 2, 1, 1],\n",
      "        [1, 1, 2, 2]]))\n",
      "tensor([[1.0000, 1.0000, 1.0000, 0.6327],\n",
      "        [0.6581, 0.8282, 0.5282, 0.8991],\n",
      "        [0.8541, 0.9537, 1.0000, 0.7003]])\n",
      "tensor([[0.1306, 0.3834, 0.2922, 0.6327],\n",
      "        [0.6581, 0.8282, 0.5282, 0.8991],\n",
      "        [0.8541, 0.9537, 0.3173, 0.7003]])\n",
      "tensor([[0.1306, 0.3834],\n",
      "        [0.5282, 0.6581],\n",
      "        [0.7003, 0.9537]])\n"
     ]
    }
   ],
   "source": [
    "#使用add相加\n",
    "a=torch.rand(3,4)\n",
    "b=torch.rand(4)\n",
    "print(a+b)\n",
    "print(torch.add(a,b))\n",
    "#使用matmul进行矩阵相乘\n",
    "print(a@b)\n",
    "\n",
    "print(torch.matmul(a,b))\n",
    "#mm函数只对2d生效\n",
    "b=torch.rand(4,3)\n",
    "print(torch.mm(a,b))\n",
    "#pow可以对tensor进行幂运算\n",
    "print(a.pow(2))\n",
    "#exp可以对tensor进行指数运算\n",
    "print(a.exp())\n",
    "#log可以对tensor进行对数运算\n",
    "print(a.log())\n",
    "#max可以对tensor进行最大值运算\n",
    "print(a.max())\n",
    "#median可以对tensor进行中位数运算\n",
    "print(a.median())\n",
    "#clamp可以对tensor进行截断运算\n",
    "print(a.clamp(0.2,0.8))\n",
    "#norm可以对tensor进行范数运算\n",
    "print(a.norm(2,dim=0))\n",
    "#sum可以对tensor进行求和运算\n",
    "print(a.sum(dim=0))\n",
    "#mean可以对tensor进行求均值运算\n",
    "print(a.mean(dim=0))\n",
    "#prod可以对tensor进行求积运算\n",
    "print(a.prod(dim=0))\n",
    "#argmin可以对tensor进行求最小值索引运算\n",
    "print(a.argmin(dim=0))\n",
    "#argmax可以对tensor进行求最大值索引运算,keepdim可以保持维度\n",
    "print(a.argmax(dim=0))\n",
    "print(a.argmax(dim=0,keepdim=True))\n",
    "#kthvalue可以对tensor进行求第k小值运算\n",
    "print(a.kthvalue(2,dim=0))\n",
    "#topk可以对tensor进行求前k大值运算\n",
    "print(a.topk(2,dim=0))\n",
    "#where 可以对tensor进行条件选择运算\n",
    "print(torch.where(a>0.5,a,torch.ones_like(a)))\n",
    "#gather可以对tensor进行索引运算,第一个参数为索引矩阵，第二个参数为索引维度\n",
    "print(a)\n",
    "print(torch.gather(a,1,torch.tensor([[0,1],[2,0],[3,1]])))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T14:31:02.986192Z",
     "end_time": "2023-04-12T14:31:03.000192Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-100.0000,  -77.7778,  -55.5556,  -33.3333,  -11.1111,   11.1111,\n",
      "          33.3333,   55.5556,   77.7778,  100.0000])\n",
      "tensor([3.7201e-44, 1.6655e-34, 7.4564e-25, 3.3382e-15, 1.4945e-05, 9.9999e-01,\n",
      "        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00])\n",
      "tensor([-1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  1.0000,  1.0000,  1.0000,\n",
      "         1.0000,  1.0000])\n",
      "tensor([  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,  11.1111,  33.3333,\n",
      "         55.5556,  77.7778, 100.0000])\n"
     ]
    }
   ],
   "source": [
    "#linspace可以生成等差数列\n",
    "a=torch.linspace(-100,100,10)\n",
    "print(a)\n",
    "#sigmoid,tanh,relu可以对tensor进行激活运算\n",
    "print(torch.sigmoid(a))\n",
    "print(torch.tanh(a))\n",
    "print(torch.relu(a))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T14:47:30.346499Z",
     "end_time": "2023-04-12T14:47:30.360498Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.])\n",
      "tensor([2.], dtype=torch.float32)\n",
      "tensor(1., grad_fn=<MseLossBackward0>)\n",
      "(tensor([2.], dtype=torch.float32),)\n",
      "tensor([2.], dtype=torch.float32)\n",
      "True\n",
      "tensor([0.3363, 0.3773, 0.2865], grad_fn=<SoftmaxBackward0>)\n",
      "(tensor([-0.1269,  0.2349, -0.1081]),)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "x=torch.ones(1)\n",
    "print(x)\n",
    "w=torch.full([1],2,dtype=torch.float32)\n",
    "print(w)\n",
    "#mse_loss可以计算均方误差,requires_grad_可以使得tensor具有梯度,需要类型是float\n",
    "w.requires_grad_()\n",
    "mse=F.mse_loss(torch.ones(1),x*w)\n",
    "print(mse)\n",
    "print(torch.autograd.grad(mse,[w]))\n",
    "#backward可以梯度反向传播,计算图有可能清除内存无法第二次梯度传播\n",
    "w=torch.full([1],2,dtype=torch.float32,requires_grad=True)\n",
    "mse=F.mse_loss(torch.ones(1),x*w)\n",
    "mse.backward()\n",
    "print(w.grad)\n",
    "a=torch.rand(3)\n",
    "#requires_grad_可以使得tensor具有梯度,需要类型是float\n",
    "a.requires_grad_()\n",
    "print(a.requires_grad)\n",
    "#softmax可以对tensor进行归一化运算\n",
    "a=torch.rand(3,requires_grad=True)\n",
    "p=F.softmax(a,dim=0)\n",
    "print(p)\n",
    "# 对矩阵使用需要backward的过程是对各个元素进行求导，然后点成梯度权重张量,retrian_graph=True可以保留计算图,但会占用内存\n",
    "p.backward(torch.tensor([1.0,0.0,0.0]),retain_graph=True)\n",
    "# autograd.grad可以对tensor进行求导运算\n",
    "print(torch.autograd.grad(p[1],[a],retain_graph=True))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T16:41:06.386175Z",
     "end_time": "2023-04-12T16:41:06.396174Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.7605)\n",
      "tensor(6.7605)\n"
     ]
    }
   ],
   "source": [
    "#cross_entropy可以对tensor进行交叉熵运算,比起null_loss,他先进行了softmax运算，再取log\n",
    "x=torch.randn(1,784)\n",
    "w=torch.randn(10,784)\n",
    "logits=x@w.t()\n",
    "pred=F.softmax(logits,dim=1)\n",
    "pred_log=torch.log(pred)\n",
    "#交叉熵需要指定多少个标签有效\n",
    "print(F.cross_entropy(logits,torch.tensor([3])))\n",
    "print(F.nll_loss(pred_log,torch.tensor([3])))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T17:50:20.174972Z",
     "end_time": "2023-04-12T17:50:20.184971Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 784])\n",
      "tensor([[0.0000e+00, 8.0869e-02, 1.5389e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         3.1340e-01, 0.0000e+00, 8.1614e-01, 0.0000e+00, 0.0000e+00, 6.0517e-01,\n",
      "         0.0000e+00, 3.1546e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9117e-02,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5137e+00,\n",
      "         0.0000e+00, 4.0553e-01, 1.2205e+00, 6.5303e-01, 3.7307e-01, 0.0000e+00,\n",
      "         7.8382e-01, 3.6775e-01, 0.0000e+00, 3.4816e-01, 7.6712e-01, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.0078e+00, 2.8184e-01, 3.1037e-01, 0.0000e+00,\n",
      "         0.0000e+00, 6.4972e-01, 7.9018e-01, 5.1738e-02, 4.9232e-01, 4.4398e-01,\n",
      "         0.0000e+00, 0.0000e+00, 1.1294e-01, 3.2224e-01, 0.0000e+00, 3.0268e-01,\n",
      "         0.0000e+00, 4.3261e-01, 0.0000e+00, 2.6344e-01, 1.4409e-01, 0.0000e+00,\n",
      "         0.0000e+00, 3.4651e-02, 0.0000e+00, 4.1353e-03, 1.9618e-01, 2.1611e-01,\n",
      "         0.0000e+00, 0.0000e+00, 7.9720e-01, 0.0000e+00, 0.0000e+00, 8.9673e-01,\n",
      "         5.2848e-02, 0.0000e+00, 0.0000e+00, 2.7237e-01, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0060e-01, 2.5235e-01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 5.8499e-01, 4.9425e-01, 6.1939e-01,\n",
      "         1.2210e+00, 7.8739e-01, 0.0000e+00, 1.6474e-01, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 9.3452e-01, 5.3956e-01, 2.0549e-01, 5.5869e-01, 5.7773e-01,\n",
      "         0.0000e+00, 0.0000e+00, 8.1000e-01, 3.1057e-01, 0.0000e+00, 0.0000e+00,\n",
      "         1.2126e+00, 8.1319e-01, 0.0000e+00, 9.8340e-01, 0.0000e+00, 2.0016e-01,\n",
      "         0.0000e+00, 1.1314e-01, 2.3888e-01, 1.2947e-01, 0.0000e+00, 0.0000e+00,\n",
      "         3.8847e-01, 0.0000e+00, 4.8142e-01, 1.1616e-01, 8.1801e-01, 5.1563e-01,\n",
      "         0.0000e+00, 0.0000e+00, 1.0392e+00, 6.4925e-02, 4.8021e-01, 0.0000e+00,\n",
      "         6.1905e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.0418e-01, 0.0000e+00,\n",
      "         0.0000e+00, 4.2666e-01, 0.0000e+00, 0.0000e+00, 1.9700e-01, 0.0000e+00,\n",
      "         1.9404e-01, 0.0000e+00, 2.4993e-01, 1.2511e+00, 1.8454e-01, 3.6795e-01,\n",
      "         0.0000e+00, 8.0948e-02, 6.6285e-01, 0.0000e+00, 5.7985e-02, 2.8596e-01,\n",
      "         4.7802e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 5.0420e-01, 2.5946e-02, 3.8840e-01, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0471e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 1.0057e-01, 0.0000e+00, 4.2364e-01, 7.0022e-02, 1.1449e-01,\n",
      "         0.0000e+00, 0.0000e+00, 4.0742e-01, 0.0000e+00, 9.7617e-01, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.0015e-01, 5.6640e-01, 9.7516e-01, 8.7513e-01,\n",
      "         2.2073e-01, 1.4946e-01, 0.0000e+00, 7.5488e-01, 2.5899e-01, 8.2734e-01,\n",
      "         0.0000e+00, 9.2441e-01],\n",
      "        [2.0501e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3716e-01, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4701e+00,\n",
      "         4.5316e-01, 5.1715e-01, 1.0072e+00, 0.0000e+00, 7.5482e-01, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 3.6536e-01, 1.1353e-01, 0.0000e+00, 3.4361e-01,\n",
      "         0.0000e+00, 0.0000e+00, 4.8266e-01, 7.8623e-02, 5.8579e-01, 1.1931e-02,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8646e-01, 0.0000e+00,\n",
      "         0.0000e+00, 9.0615e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5372e-01,\n",
      "         0.0000e+00, 6.6063e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         5.5962e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.4546e-01, 0.0000e+00, 0.0000e+00, 9.3340e-01, 2.0195e-01, 0.0000e+00,\n",
      "         0.0000e+00, 4.4285e-01, 5.9704e-01, 0.0000e+00, 0.0000e+00, 2.8788e-01,\n",
      "         2.3945e-01, 3.6458e-01, 0.0000e+00, 0.0000e+00, 4.5574e-01, 5.5545e-01,\n",
      "         0.0000e+00, 0.0000e+00, 9.7732e-01, 0.0000e+00, 0.0000e+00, 2.2063e-01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0622e-01, 1.2099e-01, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 2.1943e-01, 7.6867e-02, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 5.9312e-01, 0.0000e+00, 0.0000e+00, 5.9197e-01, 0.0000e+00,\n",
      "         5.7520e-01, 1.1061e-01, 7.0525e-01, 7.8642e-01, 0.0000e+00, 3.1787e-01,\n",
      "         0.0000e+00, 1.0044e+00, 0.0000e+00, 7.8595e-01, 4.2497e-01, 3.8234e-01,\n",
      "         5.3338e-01, 1.0412e+00, 1.7603e-01, 0.0000e+00, 5.2921e-01, 1.3715e-01,\n",
      "         1.4161e-01, 2.1237e-01, 5.5612e-01, 3.7100e-01, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 5.3729e-01, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2551e-01, 0.0000e+00, 4.3306e-01,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.9020e-01, 1.8144e-01,\n",
      "         0.0000e+00, 0.0000e+00, 1.7910e-01, 0.0000e+00, 0.0000e+00, 5.3361e-01,\n",
      "         0.0000e+00, 0.0000e+00, 2.0139e-02, 9.6118e-04, 0.0000e+00, 3.4946e-01,\n",
      "         0.0000e+00, 1.2072e+00, 5.0902e-01, 1.1110e-01, 5.3819e-01, 0.0000e+00,\n",
      "         0.0000e+00, 2.8663e-01, 9.1842e-01, 6.7839e-02, 9.7197e-02, 4.2177e-01,\n",
      "         1.6073e-01, 3.5096e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7736e-01,\n",
      "         0.0000e+00, 0.0000e+00, 6.5915e-01, 1.3246e-01, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 5.3172e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.0535e-01, 3.0711e-01, 1.8240e-01, 2.9384e-01, 0.0000e+00, 7.1474e-01,\n",
      "         3.0771e-01, 8.3984e-01, 0.0000e+00, 0.0000e+00, 5.4631e-01, 0.0000e+00,\n",
      "         2.3520e-01, 0.0000e+00, 5.0070e-01, 0.0000e+00, 9.8352e-02, 2.3456e-01,\n",
      "         6.5986e-01, 0.0000e+00]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#nn.Module可以将网络模型封装成一个类,Linear可以实现全连接层,(in,out)\n",
    "import torch.nn.functional as F\n",
    "layer1=torch.nn.Linear(784,200)\n",
    "print(layer1.weight.shape)\n",
    "x=torch.randn(2,784)\n",
    "x=layer1(x)\n",
    "#inplace=True可以使得原tensor改变\n",
    "x=F.relu(x,inplace=True)\n",
    "print(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-14T19:26:42.262748Z",
     "end_time": "2023-04-14T19:26:42.288030Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 5000 5000\n"
     ]
    }
   ],
   "source": [
    "#device可以指定运算设备\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#torch.utils.data.random_split可以将数据集切分成训练集和测试集\n",
    "train_db=torch.randn(60000,28*28)\n",
    "train_db,val_db,test_db=torch.utils.data.random_split(train_db,[50000,5000,5000])\n",
    "print(len(train_db),len(val_db),len(test_db))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-14T20:02:28.671132Z",
     "end_time": "2023-04-14T20:02:28.890931Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
